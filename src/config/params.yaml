model:
  d_model: 512
  nhead: 8
  num_encoder_layers: 6
  num_decoder_layers: 6
  dim_feedforward: 2048
  dropout: 0.1
  max_seq_length: 128

training:
  batch_size: 32
  learning_rate: 0.0001
  warmup_steps: 8000
  weight_decay: 0.01
  epochs: 10
  accumulation_steps: 2